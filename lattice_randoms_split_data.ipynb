{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "965a82d1",
   "metadata": {},
   "source": [
    "# Split the Synthetic Data to Train and Valid Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a93c51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9a15b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb52c2e",
   "metadata": {},
   "source": [
    "**Executable Block**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "c2ab9c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 13 and total number of images: 3064\n"
     ]
    }
   ],
   "source": [
    "#Assign the folder_source to original fodler for images\n",
    "folder_source = os.path.join(os.getcwd(), \"random-lattices\")\n",
    "\n",
    "#Assigning the destination folder as a working directory for train and valid split\n",
    "folder_dest = os.path.join(os.getcwd(), \"random-lattices-split\")\n",
    "\n",
    "#Create a copy of the image folder to split the images to train and valid sets\n",
    "os.makedirs(folder_dest, exist_ok = True )\n",
    "classes = os.listdir(folder_source)\n",
    "total_images = []\n",
    "\n",
    "for class_name in classes:\n",
    "    total_images.extend(os.listdir(os.path.join(folder_source, class_name)))\n",
    "    \n",
    "print(f\"Number of classes: {len(classes)} and total number of images: {len(total_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "0e4b7a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block splits the train and valid test to the amount given in train_set parameter\n",
    "train_set = 0.7\n",
    "\n",
    "train_class = []\n",
    "\n",
    "for class_name in os.listdir(folder_source):\n",
    "    \n",
    "    # first create the folders in the destinaion, train_set and valid_set folders with classes exist in folder_source\n",
    "    os.makedirs(os.path.join(folder_dest, \"train_set\", class_name), exist_ok = True)\n",
    "    os.makedirs(os.path.join(folder_dest, \"valid_set\", class_name), exist_ok = True)\n",
    "    \n",
    "    #Getting classes of images \n",
    "    image_class = os.listdir(os.path.join(folder_source, class_name))\n",
    "    \n",
    "    #shuffle the image numbers to ensure unifrom distribution of images of various features in train and valid sets\n",
    "    np.random.shuffle(image_class)   \n",
    "    \n",
    "    # The number of images for each class in train_set\n",
    "    split_index = int(len(image_class) * train_set)\n",
    "    \n",
    "    #Counting the number of images per class as imbalance data might affect the model training\n",
    "    train_class.append((class_name, split_index))\n",
    "  \n",
    "    for i in range(len(image_class)):\n",
    "        source_path = os.path.join(folder_source, class_name, image_class[i])\n",
    "\n",
    "        if i < split_index:\n",
    "            dest_path = os.path.join(folder_dest, \"train_set\", class_name, image_class[i])\n",
    "        \n",
    "        else:\n",
    "            dest_path = os.path.join(folder_dest, \"valid_set\", class_name, image_class[i])\n",
    "\n",
    "        try:\n",
    "            os.link(source_path, dest_path)\n",
    "            \n",
    "        except FileExistsError:\n",
    "            os.replace(dest_path, dest_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "d7fe35cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cubic_bcc', 100),\n",
       " ('cubic_bcc_2atom', 201),\n",
       " ('hexagon', 226),\n",
       " ('hexagon_2atom', 226),\n",
       " ('ortho_body_centered', 179),\n",
       " ('ortho_face_centered', 179),\n",
       " ('teteragonal_body_center', 89),\n",
       " ('teteragonal_c', 179),\n",
       " ('teteragonal_face', 201),\n",
       " ('teteragonal_face_bcc', 100),\n",
       " ('teteragonal_face_bcc_2atom', 100),\n",
       " ('teteragonal_reg_2atom', 179),\n",
       " ('triclinic_rhomboh', 179)]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "94173f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "926"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob(os.path.join(folder_dest, \"valid_set\") + \"/*/*.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
